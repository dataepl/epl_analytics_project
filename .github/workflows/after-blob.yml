name: Build dbt after Blob

on:
  repository_dispatch:
    types: [blob-created]

concurrency:
  group: dbt-epl
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      DBT_THREADS: ${{ secrets.DBT_THREADS || 4 }}
      # From Logic App payload:
      FILE_URL: ${{ github.event.client_payload.blob_url }}
      FILE_NAME: ${{ github.event.client_payload.file_name }}
      EVENT_TIME: ${{ github.event.client_payload.event_time }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core dbt-snowflake snowflake-connector-python

        # Make sure these are defined at job or workflow level.
        # env:
        #   SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        #   SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        #   SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        #   SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
        #   SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
        #   DBT_THREADS: 4              # default; can be overridden per-run
        #   DBT_TARGET: ci              # optional: lets you switch target later
      
      - name: Write dbt profile (~/.dbt/profiles.yml)
        run: |
          # Create the .dbt directory for the runner's home
          mkdir -p ~/.dbt

          # Use a *quoted* heredoc so the shell doesn't expand anything here.
          # dbt will render the Jinja {{ ... }} expressions at runtime.
          cat > ~/.dbt/profiles.yml <<'YAML'
          # Auto-generated by GitHub Actions. Do not commit to source control.
          epl_analytics_project:
            # Pick which output to use. Defaults to "ci".
            target: "{{ env_var('DBT_TARGET', 'ci') }}"
      
            outputs:
              # CI target used by this workflow
              ci:
                type: snowflake
                # Pull all credentials from environment variables (GitHub Secrets).
                account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
                user: "{{ env_var('SNOWFLAKE_USER') }}"
                password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
                role: "{{ env_var('SNOWFLAKE_ROLE') }}"
                warehouse: "{{ env_var('SNOWFLAKE_WAREHOUSE') }}"
                database: EPL
                schema: staging
                client_session_keep_alive: false
      
                # IMPORTANT: must be an integer, so cast env var to int.
                threads: "{{ env_var('DBT_THREADS', '4') | as_number }}"
      
              # Optional: production target you could switch to later by setting DBT_TARGET=prod
              prod:
                type: snowflake
                account: "{{ env_var('SNOWFLAKE_ACCOUNT') }}"
                user: "{{ env_var('SNOWFLAKE_USER') }}"
                password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
                role: "{{ env_var('SNOWFLAKE_ROLE') }}"
                warehouse: "{{ env_var('SNOWFLAKE_WAREHOUSE') }}"
                database: EPL
                schema: marts
                client_session_keep_alive: false
                threads: "{{ env_var('DBT_THREADS', '4') | as_number }}"
          YAML
      
      # - name: Gate until Snowpipe loaded this file
      #   run: |
      #     echo "Waiting on file: $FILE_NAME from $FILE_URL"
      #     python .github/scripts/gate_until_loaded.py --table "RAW.SOLUTION_BASE" --file "$FILE_NAME" --timeout 1800

      - name: Determine target table
        id: determine_table
        run: |
          echo "Determining table for file: $FILE_NAME"
          if [[ "$FILE_NAME" == *"__Solution.csv"* ]]; then
            echo "Detected Solution file"
            echo "table=RAW.SOLUTION_BASE" >> $GITHUB_OUTPUT
          elif [[ "$FILE_NAME" == *"__Routes.csv"* ]]; then
            echo "Detected Routes file"
            echo "table=RAW.ROUTES_BASE" >> $GITHUB_OUTPUT
          else
            echo "ERROR: Unknown file type: $FILE_NAME"
            echo "Expected filename to contain either '__Solution.csv' or '__Routes.csv'"
            exit 1
          fi

      - name: Gate until Snowpipe loaded this file
        run: |
          echo "Waiting on file: $FILE_NAME from $FILE_URL"
          echo "Target table: ${{ steps.determine_table.outputs.table }}"
          python .github/scripts/gate_until_loaded.py \
            --table "${{ steps.determine_table.outputs.table }}" \
            --file "$FILE_NAME" \
            --timeout 1800

      - name: dbt debug
        working-directory: epl_analytics_project
        run: dbt debug --target ci

      - name: Build (staging + downstream marts)
        working-directory: epl_analytics_project
        run: dbt build --target ci

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dbt-logs
          path: |
            target/*
            logs/*
          if-no-files-found: ignore
